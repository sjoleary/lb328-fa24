[
  {
    "objectID": "A02_USGSgages.html#water-stage-and-water-flow",
    "href": "A02_USGSgages.html#water-stage-and-water-flow",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.1 Water stage and water flow",
    "text": "2.1 Water stage and water flow\nTime series of water stage and water flow are two measurements of water that can be used to describe the hydrological regime in a river or stream.\n\nThe water level or gage height in a stream or river is measured in relation to a fixed reference point. In the US this is typically measured in feet.\nThe water flow (stream flow or discharge) is the amount of water that passes a specific point in a stream or river during a specific time period is typically measure in feet per second (cfs) or cubic meters per second (cms).\n\n\n\n\n\n\n\nConsider this\n\n\n\nConsider how water stage and stream flow are related. Argue which parameter you think is more informative discuss what that information can be used for. Speculate what methods and types of instruments you could use to determine each of these metrics.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe water stage is used to predict water flow which is more difficult to measure directly. To do this you need to develop a stage-discharge rating curve for a site by measuring both water level and streamflow over a range of flows, this curve can then be used to calculate water flow measured from water levels.\nWater stage is measured using a variety of methods, including\n\nPressure transducers\nStaff gages\nCrest stage gages\nMeasure downs from a defined point\nCameras\nWater level radar\n\n\n\n\nHere are two articles from the USGS to give you an overview of their efforts to monitor streamflow in the United States:\n\nStreamgaging Basics\nHow Streamflow is Measured\n\n\n\n\n\n\n\nConsider this\n\n\n\nDiscuss what factors and mechanisms cause changes in streamflow. Categorize them as natural or human-induced. Rank them in terms you think are the most important in general and specifically for the Piscataquog River compared to its headwater streams.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRead over this article from USGS discussing stream flow and the water cycle\nHere is the list of mechanisms they list:\nNatural mechanisms\n\nRunoff from rainfall and snowmelt\nEvaporation from soil and surface-water bodies\nTranspiration by vegetation\nGroundwater discharge from aquifers\nGroundwater recharge from surface-water bodies\nSedimentation of lakes and wetlands\nFormation or dissipation of glaciers, snowfields, and permafrost\n\nHuman-induced mechanisms\n\nSurface-water withdrawals and transbasin diversions\nRiver-flow regulation for hydropower and navigation\nConstruction, removal, and sedimentation of reservoirs and stormwater detention ponds\nStream channelization and levee construction\nDrainage or restoration of wetlands\nLand-use changes such as urbanization that alter rates of erosion, infiltration, overland flow, or evapotranspiration\nWastewater outfalls\nIrrigation\nWastewater return flow\n\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nDiscuss problems that could be associated with too much discharge and too little discharge.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nLow discharge means that little water is available for uses such as irrigation. It also results in fragmenting the habitat and for example would block the passage of anadromous fishes.\nToo much discharge means flooding."
  },
  {
    "objectID": "A02_USGSgages.html#exploring-variability-in-stream-flow",
    "href": "A02_USGSgages.html#exploring-variability-in-stream-flow",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.2 Exploring variability in stream flow",
    "text": "2.2 Exploring variability in stream flow\nLet’s start by taking a peak at publicly available data sets that characterize stream flow. In this activity we will use data from the United States Geologic Survey (or USGS) network of stream gaging stations. The USGS is a governmental organization established in 1879, as part of the Department of the Interior. Originally tasked with the classification and mapping of United States public lands (and assessment of their mineral resources), the USGS has since expanded their role as a provider of impartial information on the status of ecosystems in the United States. See http://www.usgs.gov for more details.\n\n2.2.1 Viewing and accessing data\nStart by Navigate to the USGS Water Dashboard\nNotice the colored dots, depicting real-time conditions at stream gages nationwide. The dots are colored to show you if the streamflow is unusually high or low for this day of the year.\n\n\n\n\n\n\nGive it a try\n\n\n\nClick on “legend” at the upper right to see what the colors mean.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nRed colors are unusually low; blue colors are unusually high.\nFor example, the dark blue color indicates that the flow is at or above the 90th percentile, which tells you that at least 90% of the flows measured on this day in the past were lower. Put another way, flow is high enough to earn the dark blue dot only about 10% of the time.\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nGet an overview of the continental US - are there patterns you can discern in terms of where locations are experiencing especially high or especially low discharge?\n\n\nClicking on any of the colored dots to bring up a pop-up window with a plot of discharge over the past week.\n\n\n\n\n\n\nGive it a try\n\n\n\nTry this now, then close the pop-up window when you are finished.\n\n\nLet’s determine where the USGS is monitoring the Piscataquog River here in New Hampshire. Zoom into the Goffstown/New Boston Area to fin the South Branch Piscataquog River gaging station. Click on it to pull up the pop up window.\nAt the top of the pop-up window, click the link to open the Site Page, which is a more detailed description of the site.\nTake a look at the data available and then scroll back to the top to see the different types of data that we can show. Leaving the range at 7 days, select “Discharge, cubic feet per second” to see a plot showing how discharge has changed over the past week.\n\n\n\n\n\n\nExplore the data set\n\n\n\nLook at the discharge data. How variable was discharge over the past week?\nYou can answer this in several ways. First, what was the range (the maximum minus the minimum) of the data? Another good way to think about variability is to think about percent change. First, estimate the mean value of the data by looking at the plot. Approximately how much higher (as a percent) are the highest discharges?\nWhere you clicked the box to select discharge data, check the box that says “Select data to graph on second y axis,” and choose water temperature. Look at the temperature graph. Based on this graph, what probably drives temperature changes? Do you think there is any relationship between temperature and discharge? If so, what do you think it might be?\nWhen discharge is high enough, flooding occurs. Is the discharge you observe here unusually high? Unusually low? Typical for the region? Can we answer these questions with only a week’s worth of data?\n\n\nLet’s think about seasonal patterns in stream flow.\n\n\n\n\n\n\nExplore the data set\n\n\n\nWe might expect flow in a stream to change seasonally. After all, most (or all) of the streamflow that you observe originated as rain and snow falling in the watershed, and precipitation in most places is seasonally variable. Let’s take a look at how streamflow changes over an entire year to see what happens.\nStill looking at both discharge and temperature data, go back to the top and change the time range to 1 Year. It may take a minute to load all of the data.\nTemperature is high in summer and low in winter, as you might expect – but what month was the warmest? What about discharge? Was it the same all year? What months had the highest discharge? The lowest?"
  },
  {
    "objectID": "A02_USGSgages.html#exploring-the-relationship-of-precipitation-and-discharge",
    "href": "A02_USGSgages.html#exploring-the-relationship-of-precipitation-and-discharge",
    "title": "2  Characterizing the hydrological regime of the Piscataquog",
    "section": "2.3 Exploring the relationship of precipitation and discharge",
    "text": "2.3 Exploring the relationship of precipitation and discharge\nPrecipitation is arguably one of the key mechanisms impacting stream discharge. Not only do levels and intensity of precipitation events vary across a year. However, there are a variety of factors that will alter how precipitation impacts the flow regimes of streams.\nEven in systems where there is little urbanization differences in the type of vegetation and ground cover present will modify t he impact of precipitation. For example, here in the Northeast we have certain times of the year where the vegetation is active and growing which means that it is pulling moisture out of the soil and some of that water then evaporates off of the leaf surfaces (Evapotranspiration). When the ground is soft and absorbent water can seep in but during large parts of the year the ground is frozen. Ground cover might consist of newly-fallen leaves in the Fall, while in the Winter it is covered with snow. All these factors will alter how much and how quickly precipitation enters a stream.\n\n2.3.1 Download the discharge data set\nOn the top menu of the site page, click on Data Inventory and select daily data.\nLet’s set up how we want to format our data:\n\nIn the Box for Available Parameters select Discharge(Mean).\nfor output format select Tab-separated.\nfor days type in 365 to give us a years worth of data.\n\nOnce you are all set click the Go button\nThis will open a new page with your data. Right click and select Save As (or use Ctrl + S). And save the data in your 01_watershed/data folder as piscat_365.txt.\n\n\n2.3.2 Download weather data\nNow, let’s find some weather data.\nGo to the NOAA National Centers for Environmental Information.\nIn the top menu click on Data Sets, then expand the Daily Summaries drop down.\nNow select the Search Tool. Which will open a page we can use to query precipiation data that is representative of the Piscataquog near our USGS gage site.\nWe downloaded a years worth of discharge data, so we will want an equivalent data set. Set the begin date to one year ago and the end date to the most recent data.\nIn the Search For box use the drop down to change to City and search for Goffstown, NH. Then use the map to select a weather station that is represenative of our location. By selecting Add to Cart.\nYou should now see 1 item in your cart in the top right of the screen. Click on your Cart. In the select Cart Options select the Custom GHCN-Daily CSV format. And double check your Date Range.\nClick Continue. In the select data types for custom output, expand the Precipitation section and select only Precipitation (PRCP).\nClick Continue. Enter your email (twice) and click Submit Order. You will receive an email confirming your order and then you, we’ve got a tiny data set we’ve requested so our order should not take too long to process.\nYou can also click on the Check order button and if it has processed you can download the data set from there.\nAfter you download the data, rename it man_precipitation.csv1 and move it into your 01_watersheds/data folder.1 You shouldn’t have to change the file ending"
  },
  {
    "objectID": "A02_USGSgages.html#visualize-compare-our-data-sets",
    "href": "A02_USGSgages.html#visualize-compare-our-data-sets",
    "title": "2  Characterizing the hydrological regime of the Piscataquog",
    "section": "2.4 Visualize & Compare our data sets",
    "text": "2.4 Visualize & Compare our data sets\nWell, that was exciting… Now that we have our data in hand, let’s take a look at what we find.\n\n\n\n\n\n\nConsider this\n\n\n\nBefore we start:\n\nDiscuss with your group how we should visualize the discharge and the precipitation data to get an overview of how these have changed over the year.\nThink about how we could determine “typical flow”, “high flow”, “low flow”.\nArgue what patterns you might expect to see in terms of how these patterns are related.\n\n\n\nLet’s start by pulling in our discharge data and visualizing it (you’ve already sneak peaked what it looks like when we were exploring the real time data).\n\n# read libraries\nlibrary(readr)\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.3.1\n\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\nlibrary(lubridate)\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(tidyr)\nlibrary(dplyr)\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\nlibrary(patchwork)\n\nWarning: package 'patchwork' was built under R version 4.3.1\n\nlibrary(plotly)\n\nWarning: package 'plotly' was built under R version 4.3.2\n\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(knitr)\n\nWarning: package 'knitr' was built under R version 4.3.2\n\n# read data set\ndischarge &lt;- read_delim(\"data/piscat_365.txt\",\n                        skip = 27,\n                        delim = \"\\t\",\n                        col_names = c(\"agency\", \"site_no\", \"date\", \"discharge_cfs\", \"flag\"))\n\nRows: 365 Columns: 5\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr  (3): agency, site_no, flag\ndbl  (1): discharge_cfs\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# check data\nhead(discharge) %&gt;%\n  kable()\n\n\n\n\nagency\nsite_no\ndate\ndischarge_cfs\nflag\n\n\n\n\nUSGS\n01091000\n2023-09-05\n39.5\nA\n\n\nUSGS\n01091000\n2023-09-06\n36.2\nA\n\n\nUSGS\n01091000\n2023-09-07\n34.1\nA\n\n\nUSGS\n01091000\n2023-09-08\n32.6\nA\n\n\nUSGS\n01091000\n2023-09-09\n38.3\nA\n\n\nUSGS\n01091000\n2023-09-10\n52.6\nA\n\n\n\n\n\nNext we can visualize it:\n\nggplot(discharge, aes(x = date, y = discharge_cfs)) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Date\", y = \"Daily Mean Discarge (cubic feet per second)\") +\n  theme_classic()\n\n\n\n\nLet’s take a look at our precipitation data over the same time period.\n\n# read data\nprecip &lt;- read_delim(\"data/man_precipitation.csv\",\n                     delim = \",\") %&gt;%\n  clean_names()\n\nRows: 7076 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): STATION, NAME\ndbl  (1): PRCP\ndate (1): DATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# check data\nhead(precip)\n\n# A tibble: 6 × 4\n  station     name                       date        prcp\n  &lt;chr&gt;       &lt;chr&gt;                      &lt;date&gt;     &lt;dbl&gt;\n1 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-04   0  \n2 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-05   0  \n3 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-06   0  \n4 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-07   0  \n5 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-08   0  \n6 US1NHHL0049 MONT VERNON 1.3 SSW, NH US 2023-09-09   0.2\n\n\nNow let’s plot this data:\n\nggplot(precip, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"darkblue\") +\n  theme_classic()\n\nWarning: Removed 116 rows containing missing values (`position_stack()`).\n\n\n\n\n\nWe can plot both into the same figure if we would like\n\np1 &lt;- ggplot(discharge, aes(x = date, y = discharge_cfs)) +\n  geom_line() +\n  geom_point() +\n  labs(x = \" \", y = \"Daily Mean Discarge [cf]\") +\n  theme_classic()\n\np2 &lt;- ggplot(precip, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"darkblue\") +\n  labs(x = \"Date\", y = \"daily total precipitation\") +\n  theme_classic()\n\np1 / p2\n\nWarning: Removed 116 rows containing missing values (`position_stack()`).\n\n\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nDescribe each figure on its own and then compare and contrast the two figures:\n\nDo your predictions about relationships hold water (sorry, couldn’t) resist?\nIf not, what could be contributing factors? other mechanisms impacting discharge?\nConsider differences in season (winter, spring, summer, fall) and different types of precipitation.\nThink about intensity and duration of rain events.\nConsider the temporal scale at which mechanisms impacting discharge might vary: type of soil, amount/type of vegetation, presence of impervious surfaces, temperature, ground cover, saturation of soil,…\n\nSummarize your results and insights - hang onto these, you will likely want to refer to them when we think about how we want to design our next poster board iteration."
  },
  {
    "objectID": "A02_USGSgages.html#characterizing-changes-in-discharge-over-time",
    "href": "A02_USGSgages.html#characterizing-changes-in-discharge-over-time",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.5 Characterizing changes in discharge over time",
    "text": "2.5 Characterizing changes in discharge over time\nOne question that you have thrown out repeatedly is whether the conditions are changing over time due to climate change. We can take a look at this.\n\n2.5.1 Long-term Piscataquog River changes in stream flow.\n\n\n\n\n\n\nConsider this\n\n\n\nHow do you expect climate change to alter patterns of precipitation? What other factors could be changing due to climate change that could impact stream discharge?\n\n\nIn the data sets that we have looked at previously, we were looking at daily means - this introduces a lot of variability into the data set. Instead, we can access Monthly Statistics, another strategy we can use is to assess summer and winter months separately.\nLet’s go back to the USGS Water Dashboard and pull up the South Branch Piscataquog River USGS station. Select the Site Page and from Data Inventory select Monthly Statistics.\nNext, check the box next to discharge and leave the date range blank to get the entire date range. Choose tab-separated data in YYYY-MM-DD format, and save to file. Once you click Submit, a text file called “download” will be saved to your computer (likely the Downloads file.\nRename it Piscat_monthly.txt and move it to your 01_watershed/data folder.\nLet’s read that file into R.\n\nmonthly &lt;- read_delim(\"data/Piscat_monthly.txt\",\n                      skip = 37,\n                      col_names = c(\"agency\", \"site_no\", \"parameter\", \"ts_id\",\n                                    \"year\", \"month\", \"mean_monthly\")) %&gt;%\n  select(year, month, mean_monthly) %&gt;%\n  mutate(month = month(month, label = TRUE))\n\nhead(monthly) %&gt;%\n  kable()\n\n\n\n\nyear\nmonth\nmean_monthly\n\n\n\n\n1940\nAug\n21.8\n\n\n1940\nSep\n24.4\n\n\n1940\nOct\n16.9\n\n\n1940\nNov\n111.9\n\n\n1940\nDec\n153.2\n\n\n1941\nJan\n131.2\n\n\n\n\n\nNow we can plot the discharge by month.\n\nggplot(monthly, aes(x = year, y = mean_monthly, color = month)) +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  geom_point() +\n  labs(x = \"month\", y = \"mean monthly discharge\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nDiscuss your results.\n\n\nThis is a bit messy, so let’s pick February to represent winter and re-plot our data.\n\nfeb &lt;- monthly %&gt;%\n  filter(month == \"Feb\")\n\nggplot(feb, aes(x = year, y = mean_monthly)) +\n  stat_smooth(method = \"lm\") +\n  geom_point() +\n  labs(x = \"month\", y = \"mean discharge for February\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\nAnd let’s pick August to represent summer.\n\naug &lt;- monthly %&gt;%\n  filter(month == \"Aug\")\n\nggplot(aug, aes(x = year, y = mean_monthly)) +\n  stat_smooth(method = \"lm\") +\n  geom_point() +\n  labs(x = \"month\", y = \"mean discharge for August\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nCompare and contrast the two figures and describe your results: What patterns do you see?\n\n\nWe can also quickly run a linear regression to determine whether our results are significantly different from a random distribution.\nLet’s take a look at our February data set:\n\nlm(mean_monthly ~ year, data = feb) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = mean_monthly ~ year, data = feb)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-153.19  -70.81  -25.72   29.49  296.72 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept) -1387.9232  1026.1698  -1.353    0.182\nyear            0.7966     0.5192   1.534    0.131\n\nResidual standard error: 105.7 on 52 degrees of freedom\nMultiple R-squared:  0.04331,   Adjusted R-squared:  0.02491 \nF-statistic: 2.354 on 1 and 52 DF,  p-value: 0.131\n\n\nAnd now let’s look at August:\n\nlm(mean_monthly ~ year, data = aug) %&gt;%\n  summary()\n\n\nCall:\nlm(formula = mean_monthly ~ year, data = aug)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-67.31 -26.55 -10.04  19.61 168.76 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) -1424.4738   431.3169  -3.303  0.00172 **\nyear            0.7435     0.2183   3.405  0.00127 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 44.47 on 53 degrees of freedom\nMultiple R-squared:  0.1795,    Adjusted R-squared:  0.164 \nF-statistic:  11.6 on 1 and 53 DF,  p-value: 0.001267\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nDescribe your results. Discuss with your group how to interpret the p-value and R2 value.\nNow interpret your results and discuss what you have learned about the change in monthly discharge over time in the Piscataquog.\nConsider whether you think this pattern would be stronger, weaker or the same for headwater streams."
  },
  {
    "objectID": "A02_USGSgages.html#acknowledgements",
    "href": "A02_USGSgages.html#acknowledgements",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.6 Acknowledgements",
    "text": "2.6 Acknowledgements"
  },
  {
    "objectID": "A02_USGSgages.html#exploring-the-relationship-of-precipitation-and-discharge-in-the-piscataquog-river",
    "href": "A02_USGSgages.html#exploring-the-relationship-of-precipitation-and-discharge-in-the-piscataquog-river",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.3 Exploring the relationship of precipitation and discharge in the Piscataquog River",
    "text": "2.3 Exploring the relationship of precipitation and discharge in the Piscataquog River\nPrecipitation is arguably one of the key mechanisms impacting stream discharge. Not only do levels and intensity of precipitation events vary across a year. However, there are a variety of factors that will alter how precipitation impacts the flow regimes of streams.\nEven in systems where there is little urbanization differences in the type of vegetation and ground cover present will modify t he impact of precipitation. For example, here in the Northeast we have certain times of the year where the vegetation is active and growing which means that it is pulling moisture out of the soil and some of that water then evaporates off of the leaf surfaces (Evapotranspiration). When the ground is soft and absorbent water can seep in but during large parts of the year the ground is frozen. Ground cover might consist of newly-fallen leaves in the Fall, while in the Winter it is covered with snow. All these factors will alter how much and how quickly precipitation enters a stream.\n\n2.3.1 Download the discharge data set\nOn the top menu of the site page, click on Data Inventory and select daily data.\nLet’s set up how we want to format our data:\n\nIn the Box for Available Parameters select Discharge(Mean).\nfor output format select Tab-separated.\nfor days type in 365 to give us a years worth of data.\n\nOnce you are all set click the Go button\nThis will open a new page with your data. Right click and select Save As (or use Ctrl + S). And save the data in your 01_watershed/data folder as piscat_365.txt.\n\n\n2.3.2 Download weather data\nNow, let’s find some weather data.\nGo to the NOAA National Centers for Environmental Information.\nIn the top menu click on Data Sets, then expand the Daily Summaries drop down.\nNow select the Search Tool. Which will open a page we can use to query precipiation data that is representative of the Piscataquog near our USGS gage site.\nWe downloaded a years worth of discharge data, so we will want an equivalent data set. Set the begin date to one year ago and the end date to the most recent data.\nIn the Search For box use the drop down to change to City and search for Goffstown, NH. Then use the map to select a weather station that is representative of our location. By selecting Add to Cart.\nYou should now see 1 item in your cart in the top right of the screen. Click on your Cart. In the select Cart Options select the Custom GHCN-Daily CSV format. And double check your Date Range.\nClick Continue. In the select data types for custom output, expand the Precipitation section and select only Precipitation (PRCP).\nClick Continue. Enter your email (twice) and click Submit Order. You will receive an email confirming your order and then you, we’ve got a tiny data set we’ve requested so our order should not take too long to process.\nYou can also click on the Check order button and if it has processed you can download the data set from there.\nAfter you download the data, rename it man_precipitation.csv1 and move it into your 01_watersheds/data folder.1 You shouldn’t have to change the file ending\n\n\n2.3.3 Visualize & Compare our data sets\nWell, that was exciting… Now that we have our data in hand, let’s take a look at what we find.\n\n\n\n\n\n\nConsider this\n\n\n\nBefore we start:\n\nDiscuss with your group how we should visualize the discharge and the precipitation data to get an overview of how these have changed over the year.\nThink about how we could determine “typical flow”, “high flow”, “low flow”.\nArgue what patterns you might expect to see in terms of how these patterns are related.\n\n\n\nLet’s start by pulling in our discharge data and visualizing it (you’ve already sneak peaked what it looks like when we were exploring the real time data).\n\n# read libraries\nlibrary(readr)\nlibrary(janitor)\nlibrary(lubridate)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(plotly)\nlibrary(knitr)\n\n# read data set\ndischarge &lt;- read_delim(\"data/piscat_365.txt\",\n                        skip = 27,\n                        delim = \"\\t\",\n                        col_names = c(\"agency\", \"site_no\", \"date\", \"discharge_cfs\", \"flag\"))\n\n# check data\nhead(discharge) %&gt;%\n  kable()\n\n\n\n\nagency\nsite_no\ndate\ndischarge_cfs\nflag\n\n\n\n\nUSGS\n01091000\n2023-09-05\n39.5\nA\n\n\nUSGS\n01091000\n2023-09-06\n36.2\nA\n\n\nUSGS\n01091000\n2023-09-07\n34.1\nA\n\n\nUSGS\n01091000\n2023-09-08\n32.6\nA\n\n\nUSGS\n01091000\n2023-09-09\n38.3\nA\n\n\nUSGS\n01091000\n2023-09-10\n52.6\nA\n\n\n\n\n\nNext we can visualize it using a line graph:\n\nggplot(discharge, aes(x = date, y = discharge_cfs)) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Date\", y = \"Daily Mean Discarge (cubic feet per second)\") +\n  theme_classic()\n\n\n\n\nLet’s take a look at our precipitation data over the same time period.\n\n# read data\nprecip &lt;- read_delim(\"data/man_precipitation.csv\",\n                     delim = \",\") %&gt;%\n  clean_names()\n\n# check data\nhead(precip) %&gt;%\n  kable()\n\n\n\n\nstation\nname\ndate\nprcp\n\n\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-04\n0.0\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-05\n0.0\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-06\n0.0\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-07\n0.0\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-08\n0.0\n\n\nUS1NHHL0049\nMONT VERNON 1.3 SSW, NH US\n2023-09-09\n0.2\n\n\n\n\n\nNow let’s plot this data set as a bar graph:\n\nggplot(precip, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"darkblue\") +\n  labs(x = \"date\", y = \"daily total precipitation\") +\n  theme_classic()\n\n\n\n\nWe can plot both into the same figure if we would like. To do this we will use the patchwork package which allows us to create objects that will hold our individual figures and then we can plot them underneath each other for easier comparison.\n\np1 &lt;- ggplot(precip, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"darkblue\") +\n  labs(x = \"\", y = \"daily total precipitation\") +\n  theme_classic()\n\np2 &lt;- ggplot(discharge, aes(x = date, y = discharge_cfs)) +\n  geom_line() +\n  geom_point() +\n  labs(x = \"Date\", y = \"daily mean discarge [cfs]\") +\n  theme_classic()\n\n# combine figures under each other\np1 / p2\n\n\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nDescribe each figure on its own and then compare and contrast the two figures:\n\nDo your predictions about relationships hold water (sorry, couldn’t) resist?\nIf not, what could be contributing factors? other mechanisms impacting discharge?\nConsider differences in season (winter, spring, summer, fall) and different types of precipitation.\nThink about intensity and duration of rain events.\nConsider the temporal scale at which mechanisms impacting discharge might vary: type of soil, amount/type of vegetation, presence of impervious surfaces, temperature, ground cover, saturation of soil,…\n\nSummarize your results and insights - hang onto these, you will likely want to refer to them when we think about how we want to design our next poster board iteration."
  },
  {
    "objectID": "A02_USGSgages.html#exploring-patterns-of-water-flow-in-headwater-streams.",
    "href": "A02_USGSgages.html#exploring-patterns-of-water-flow-in-headwater-streams.",
    "title": "2  Characterizing the hydrological regime of the Piscataquog river & headwater streams",
    "section": "2.4 Exploring patterns of water flow in headwater streams.",
    "text": "2.4 Exploring patterns of water flow in headwater streams.\nWe are currently monitoring water level changes in five headwater streams using data loggers. These are attached to a rock and placed in the bottom of the headwwater streams, typically in pools where there is less chance for them to be washed out.\n\nAvery Brook (AVB)\nSchoolhouse Brook (SHB)\nWhiting Brook (WHB)\nBrennan Brook (BRB)\nRand Brook (RAB)\n\nAt Rand Brook we have a paired logger recording air temperature and pressure. We can calculate the difference between air and water pressure and divide that by the product of the density of water and the gravitational pull to determine the absolute height of the water column above the data logger and track changes in water levels over time.\n\n\n\n\n\n\nConsider this\n\n\n\nConsider about the relationship of water flow, water level, and stream discharge and evaluate how useful this data is to understand changes in stream flow over time and possible caveats in interpreting this information.\nDescribe additional measurements you would need to make this information more useful.\n\n\n\n2.4.1 Rand Brook\nLet’s take a look at the data from Rand Brook. In addition to reading in the data, we will split the time stamp into date and time, to calculate mean daily water level. Then we will extract the year into a separate column as well as determine the day of the year.\n\nrab &lt;- read_delim(\"data/RAB_water-level.tsv\", delim = \"\\t\") %&gt;% # read data set\n  mutate(date = as_date(date_time)) %&gt;%                         # extract date\n  group_by(date) %&gt;%                                            # group by date\n  summarize(mean_daily_level_cm = mean(water_level_cm)) %&gt;%     # calculate daily mean\n  mutate(yday = yday(date),                                     # determine day of year\n         year = as.character(year(date)))                       # make year qualitative\n\nNow we can plot the change in water level over the course of a year.\n\nggplot(rab, aes(x = yday, y = mean_daily_level_cm, color = year)) +\n  geom_line() +\n  geom_point(size = 0.5) +\n  scale_color_manual(values = c(\"#3E2F5B\", \"#136F63\", \"#E0CA3C\", \"#F34213\")) +\n  labs(x = \"day of the year\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\n\nThat’s a bit tricky to see so we can also split each year into a separate panel:\n\nggplot(rab, aes(x = yday, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") +\n  facet_grid(. ~ year) +\n  labs(x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\n\nOr we could just plot it by date:\n\nggplot(rab, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\nrab_plot &lt;- ggplot(rab, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(Title = \"Rand Brook\",\n       x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\n\n\n2.4.2 Compare to Precipitation Data\nLet’s compare our data sets to the precipitation over that time. Don’t worry, I have already downloaded the data through the NOAA climate page, it is waiting for you in the google folder.\n\nprecip_2021 &lt;- read_delim(\"data/precipitat_2021-2024.csv\", delim = \",\") %&gt;%\n  clean_names()\n\nLet’s take a look:\n\nggplot(precip_2021, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"#3E2F5B\", fill = \"#3E2F5B\") +\n  labs(x = \"date\", y = \"mean daily precipitation\") +\n  theme_classic()\n\n\n\nprec_plot &lt;- ggplot(precip_2021, aes(x = date, y = prcp)) +\n  geom_bar(stat = \"identity\", color = \"#3E2F5B\", fill = \"#3E2F5B\") +\n  labs(x = \"date\", y = \"mean daily precipitation\") +\n  theme_classic()\n\n\n\n\n\n\n\nGive it a try\n\n\n\nUse your new found skills to read in data and plot it to repeat the same process we just completed for Rand Brook for the remaining locations.\nYou should also find a daily discharge file for the same time period for the Piscataquog in our Google folder.\nCreate a plot that contains the precipitation data as well as the water level data for each headwater stream location. You will notice that there are some gaps in the data because … well, that’s just how science goes sometimes. We tried.\nCompare and contrast the headwater streams to each other and the precipitation data and then compare your results to what you learned about this relationship in the Piscataquog River.\nSummarize your results and insights - hang onto these, you will likely want to refer to them when we think about how we want to design our next poster board iteration.\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWhiting Brook\nLet’s take a look at the data from Whiting Brook.\n\nwhb &lt;- read_delim(\"data/WHB_water-level.tsv\", delim = \"\\t\") %&gt;% # read data set\n  mutate(date = as_date(date_time)) %&gt;%                         # extract date\n  group_by(date) %&gt;%                                            # group by date\n  summarize(mean_daily_level_cm = mean(water_level_cm)) %&gt;%     # calculate daily mean\n  mutate(yday = yday(date),                                     # determine day of year\n         year = as.character(year(date)))                       # make year qualitative\n\n\nwhb_plot &lt;- ggplot(whb, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(title = \"Whiting Brook\",\n       x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\nBrennan Brook\nLet’s take a look at the data from Brennan Brook.\n\nbrb &lt;- read_delim(\"data/BRB_water-level.tsv\", delim = \"\\t\") %&gt;% # read data set\n  mutate(date = as_date(date_time)) %&gt;%                         # extract date\n  group_by(date) %&gt;%                                            # group by date\n  summarize(mean_daily_level_cm = mean(water_level_cm)) %&gt;%     # calculate daily mean\n  mutate(yday = yday(date),                                     # determine day of year\n         year = as.character(year(date)))                       # make year qualitative\n\n\nbrb_plot &lt;- ggplot(brb, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(title = \"Brennan Brook\",\n       x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\nSchoolhouse Brook\nLet’s take a look at the data from Schoolhouse Brook.\n\nsch &lt;- read_delim(\"data/SHB_water-level.tsv\", delim = \"\\t\") %&gt;% # read data set\n  mutate(date = as_date(date_time)) %&gt;%                         # extract date\n  group_by(date) %&gt;%                                            # group by date\n  summarize(mean_daily_level_cm = mean(water_level_cm)) %&gt;%     # calculate daily mean\n  mutate(yday = yday(date),                                     # determine day of year\n         year = as.character(year(date)))                       # make year qualitative\n\nsch_plot &lt;- ggplot(sch, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(title = \"Brennan Brook\",\n       x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\nAvery Brook\nLet’s take a look at the data from Schoolhouse Brook.\n\navb &lt;- read_delim(\"data/AVB_water-level.tsv\", delim = \"\\t\") %&gt;% # read data set\n  mutate(date = as_date(date_time)) %&gt;%                         # extract date\n  group_by(date) %&gt;%                                            # group by date\n  summarize(mean_daily_level_cm = mean(water_level_cm)) %&gt;%     # calculate daily mean\n  mutate(yday = yday(date),                                     # determine day of year\n         year = as.character(year(date)))                       # make year qualitative\n\navb_plot &lt;- ggplot(avb, aes(x = date, y = mean_daily_level_cm)) +\n  geom_line(color = \"#136F63\") +\n  geom_point(size = 0.5, color = \"#136F63\") + \n  labs(title = \"Brennan Brook\",\n       x = \"date\", y = \"daily mean water level [cm]\") +\n  theme_classic() + \n  theme(legend.position = \"bottom\")\n\nNow we can combine them all into one plot:\n\nprec_plot / rab_plot / sch_plot / whb_plot / brb_plot / avb_plot"
  },
  {
    "objectID": "A_stream-characterization.html#acknowledgements",
    "href": "A_stream-characterization.html#acknowledgements",
    "title": "Exploring the hydrological, physical, and chemical charateristics of headwaters in the Piscataquog water shed",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nSome of these activities borrow heavily the EDDIE Stream Discharge Module2.2 Bader, N.E., T. Meixner, C.A. Gibson, C.M. O’Reilly, and D.N. Castendyk. 26 June 2015. Project EDDIE: Stream Discharge. Project EDDIE Module 5, Version 2"
  },
  {
    "objectID": "D_set-up.html",
    "href": "D_set-up.html",
    "title": "All Biology is Computational Biology",
    "section": "",
    "text": "Even though you might not consider yourself a “computer person” at this point you cannot get around a fundamental computer literacy and ideally having a few more advance computational tools in your tool kit in the environmental sciences1.1 Given the advances in instrumentation, arguable we invented big data!\nThis semester we will explore various data sets using mapping/GIS tools that make data publicly available and explorable. We will also use R and Rstudio to explore data sets in more detail.\nHave an open and flexible mindset - R can have a steep learning curve and things might go wrong but once you get the hang of it, it is a very powerful tool with a wide range of applications. Many State and Federal agencies use R to summarize, analyze, and visualize their data sets and many of them have even created R packages to allow you to interact with their data."
  },
  {
    "objectID": "D01_intro-R.html#sec-install--set-up-r-and-rstudio-on-your-computer",
    "href": "D01_intro-R.html#sec-install--set-up-r-and-rstudio-on-your-computer",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.1 Install & Set up R and Rstudio on your computer",
    "text": "3.1 Install & Set up R and Rstudio on your computer\nIf you have already installed R and Rstudio on your laptop, make sure your R version is up to date. Whenever you open Rstudio the version will be printed in the console. In addition, you can always check what version is installed by typing sessionInfo() into your console. You should be using version 4.0.0 or later. You do not need to uninstall old version of R. If you do have to update, you will need to re-install packages (see below) for R 4.0.0\n\n3.1.1 Windows\nInstall R\n\nDownload most recent version of R for Windows here.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nInstall Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Windows XP/Vista/7/8/10.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\n\n\n3.1.2 Mac OS X\nDownload & install R\n\nGo to (CRAN)[http://cran.r-project.org/], select Download R for (Mac) OS X.\nDownload the .pkg file for your OS X version.\nRun the downloaded file to install R.\n\nDownload & install Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Mac OS X.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard."
  },
  {
    "objectID": "D01_intro-R.html#sec-get-to-know-rstudio",
    "href": "D01_intro-R.html#sec-get-to-know-rstudio",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.2 Get to know Rstudio",
    "text": "3.2 Get to know Rstudio\nRstudio is an Integrated Development Environment (IDE) that you can use to write code, navigate files, inspect objects, etc. The advantage of using an IDE is that you have access to shortcuts, visual cues, troubleshooting, navigation, and auto complete help.\n\n3.2.1 GUI Layout\nGUI stands for graphic user interface and refers to a type of user interface that allows users to interact with software applications and electronic devices through visual elements such as icons, buttons, windows, and menus, rather than using text-based command-line interfaces.\nYou have probably mostly interacted with computer programs through a GUI, where you manipulate graphical elements using a pointing device like a mouse, touch screen, or stylus. GUIs provide a more intuitive and user-friendly way for individuals to interact with computers and software because you can “see” what the effect of what you are doing is having. GUIs are a major departure from earlier text-based interfaces like command-line interfaces. They have contributed significantly to the widespread adoption of computers and software by making them more accessible to a broader range of users. GUIs are used in various types of software, from operating systems to applications like web browsers, image editors, word processors, and more.\nNot too long ago, if you had wanted to learn R or another programming language you would have been working directly on a console instead of an IDE like Rstudio which has made coding a lot more accessible to beginners because you can more easily use scripts, interactively run code and visualize data.\n\n\n\n\n\n\nProtip\n\n\n\nUse this link to access an Rstudio IDE Cheatsheet pointing out the key features using annotated impages of the different panes. You can also download a pdf version and keep a printout handy as you get used to the GUI.\n\n\nOpen Rstudio and identify the four panes in the interface (default layout).\n\nEditor (top left): Edit scripts/other documents, code can be sent directly to the console.\nR console (bottom left): Run code either by directly typing the code or sending it from the editor pane.\nEnvironment/History (top right): Contains variables/objects as you create them & full history of functions/commands that have been run.\nFiles/Plots/Packages/Help/Viewer (bottom right): Different tabs in this pane will let you explore files on your computer, view plots, loaded packages, and read manual pages for various functions.\n\nThe panes can be customized (View -&gt; Panes -&gt; Pane Layout) and you can move/re-size them using your mouse.\n\n\n\n\n\n\nHeads Up\n\n\n\nWe are going to switch to have the Console in our top right and the Environment in the bottom left which makes it easier to see your code output and your script/quarto document at the same time.\nThe easiest way to do this is to go to View -&gt; Panes -&gt; Console on Right.\n\n\nBefore we move on, let’s look at two easy ways to navigate longer documents and also communicate with others where we are in the document if we need help trouble shooting.\nFirst, take a look at the top of the Viewer Pane. There should be a button labeled Outline. You can toggle that on and off to show and outline of the headers used in a document. Using headers helps you structure your document into logical parts - it also means that you can jump to different sections.\nSecond, look at the bottom left of your Viewer pane. You should see a little orange square with a # in it, if you are reading along in your quarto document it will currently say GUI Layout next to the orange #. If you click on it, it will give you a menu where you can select not only sections based on the headers, you will also see all the code chunks numbered. If they have been given a name using the label code chunk option you will be able to see that as well.\n\n\n3.2.2 Interacting with R in Rstudio\nThink of R as a language that allows you to give your computer precise instructions (code) to follow.\n\nCommands are the instructions we are giving the computer, usually as a series of functions.\nExecuting code or a program means you are telling the computer to run it.\n\nThere are three main ways to interact with R - directly using console, script files (*.R), or code chunks embedded in R markdown (*.Rmd) or quarto files (*.qmd). We will generally be working with quarto documents this semester.\nThe console is where you execute code and see the results of those commands1. You can type your code directly into the console and hit Enter to execute it. You can review those commands in the history pane (or by saving the history) but if you close the session and don’t save the history to file those commands will be forgotten.1 You can think of the console as a super-powered calculator\nBy contrast, writing your code in the script editor either as a standard script or as a code chunk in an quarto document allows you to have a reproducible workflow (future you and other collaborators will thank you).\nExecuting an entire script, a code chunk, or individual functions from a script will run them in the console.\n\nCtrl + Enter will execute commands directly from the script editor or a code chunk. You can use this to run the line of code your cursor is currently in in the script editor or you can highlight a series of lines to execute.\nIf you are using a quarto file you can execute an entire code chunk by pressing the green arrow in the top right corner.\n\nWe will run through these options, but you can always check back here while you are getting used to R.\n\n\n\n\n\n\nProtip\n\n\n\nIf the console is ready for you to execute commands you should see a &gt; prompt. If you e.g. forget a ) you will see a + prompt - R is telling you that it is expecting further code. When this happens and you don’t know what you are missing (usually it is an unmatched quotation or parenthesis), make sure your cursor is in the console and hit the Esc key.\n\n\nFor each of our units we will have a project folder2 with an Rproject, *.qmd-files to complete lab assignments and write your lab report, along with sub-directories to hold the data and results that you will generate.2 We will use “directory” and “folder” synonymously throughout this lab handbook\nUsing Rprojects allows us to set the working directory to the folder you are currently working out of which means that for everyone the file paths will be the same. You can open an Rproj file by double clicking it in a file manager which will then open an instance of Rstudio. Alternatively, you can use the Project Icon in the top right corner of the Rstudio IDE to open an existing Rproject. If you look in the bottom left hand pane in the Files tab, the bread crumbs should lead to your project folder which has now become your working directory, i.e. all paths are relative to this location. If you navigate away from your working directory (project directory) you can quickly get back to your project directory by clicking on the project icon in the Files pane or by clicking the cog icon (More) and selecting Go to Working Directory.\n\n\n\n\n\n\nHeads Up\n\n\n\nAlways make sure that you are in the correct Rproject.\nWe solve about 50% of problems with error messages about “files not being found” and things not running as they should by making sure that you are working out of the correct project folder and loaded Rproject. You can always check by looking if the name of your Rproject is next to the Rproject icon in the top right corner of Rstudio.\n\n\nWe are going to be using quarto documents such as the one you are currently working in throughout this semester.\nAn qmd-file consists of three components:\n\nHeader: written in YAML format the header contains all the information on how to render the .qmd file.\nMarkdown Sections: written in Rmarkdown syntax.\nCode chunks: Chunks of R code (or other code such as bash, python, …). These can be run interactively while generating your document and will be rendered when knitting the document.\n\nRstudio now also has a WYSIWYG3 visual editor that will allow you to interact with quarto documents similar to the way you use a word processor to get bold, italics and similar formatting, so you do not need to learn how to write in Rmarkdown.3 What you see is what you get\nYou can use the render button in the editing pane to convert your quarto document to a wide range of formats including Word, PDF, and html.\n\n\n3.2.3 Customize Rstudio\nThere are several options to customize Rstudio including setting a theme, and other formatting preferences. You can access this using Tools &gt; Global Options. I recommend using a dark theme (it’s a lot easier on the eyes) and keeping the panes in the same positions outlined above because it will make troubleshooting a lot easier4.4 “You should see xx in the top left” is a lot more helpful if your top left looks like my top left!"
  },
  {
    "objectID": "D01_intro-R.html#sec-installing-and-using-packages-in-r",
    "href": "D01_intro-R.html#sec-installing-and-using-packages-in-r",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.3 Installing and using packages in R",
    "text": "3.3 Installing and using packages in R\n\n3.3.1 Install a package\nThink of R packages or libraries as tool kit comprising a set of functions (tools) to perform specific tasks. R comes with a set of packages already installed that gives you base R functions; you can view these and determine which have been loaded in the Packages tab in the bottom right pane. For other tasks we will need additional packages. 55 Most R packages are found in the CRAN repository and on Bioconducter, developmental packages are available on github.\nA central group of packages for data wrangling and processing form the tidyverse, described as “… an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” - We are going to heavily rely on core functions from the tidyverse to wrangle, summarize, visualize and analyze data.\nWhen you install packages they will be downloaded and installed onto your computer. Determine what your default path is using .libPaths() and change if necessary.\nThe easiest way to install packages directly in the console is to use the install.packages() function.\nExecute the code chunk below to install some libraries to get us started6 by placing your cursor somewhere in the code and hitting Ctrl + Enter or by clicking on the green arrow in the top right corner of the code chunk.6 We will install other libraries as needed down the line.\n\n# install central packages in the tidyverse\ninstall.packages(\"tidyverse\",\n                 \"janitor\",\n                 \"glue\",\n                 \"here\",\n                 \"tibble\",\n                 \"ggthemes\",\n                 \"knitr\",\n                 \"tidymodels\",\n                 \"penguins\")\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can also install packages using the Packages tab in the bottom right pane. Select the Packages tab and then click on the Install button to pull up a dialogue box. Type the packages you want to install into the Packages box and confirm using Install.\n\n\nLet’s check if you were able to successfully install those packages by ensuring you can load them. Any time you start a new R session (e.g. by closing Rstudio and restarting it), you will need to load your libraries beyond the base libraries that are automatically loaded using the library() function in order to be able to use the functions specific to that package7.7 Troubleshooting tip: if you get an error along the lines of function() cannot be found the first thing you will want to do is check if your libraries are loaded!\n\n# load library\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.1\n\n\nWarning: package 'ggplot2' was built under R version 4.3.1\n\n\nWarning: package 'purrr' was built under R version 4.3.1\n\n\nWarning: package 'dplyr' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIf you don’t see any error messages in the console along the lines of there is no package called ... you are all set. If you look in the packages tab in the lower right panel you should also see that packages such as dplyr and tidyr (two of the central tidyverse packages) now have a little check box next to them.\n\n\n3.3.2 Updating R packages\nYou should generally make sure to keep your R packages up to date as new versions include important bugfixes and additional improvements. The easiest way to update packages is to use the Update button in the Packages tab in the bottom right panel. Over the course of the semester you should not have to do this, but when you install new packages you might get message that some of your packages need to be updated which you can then either choose to do at that point or ignore.\n\n\n\n\n\n\nHeads Up\n\n\n\nBe aware that updating packages might break some code you have previously written. For most of what we will be doing this should not be the case. If you used R for a previous course, make sure to update you packages at the beginning of this course and we should be set for the semester."
  },
  {
    "objectID": "D01_intro-R.html#sec-r-is-all-about-objects",
    "href": "D01_intro-R.html#sec-r-is-all-about-objects",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.4 R is all about Objects",
    "text": "3.4 R is all about Objects\nYou can think of the R console as a super-powerful calculator.\nYou can get output from R by simply typing math directly into the console.\n\n13 + 29\n\n[1] 42\n\n\nor\n\n546 / 13\n\n[1] 42\n\n\nWell that’s fun - but not super helpful in our context.\nIn the R programming language, an object is a fundamental concept used to store, manipulate, and represent data. Everything in R is treated as an object, whether it’s a number (numeric), a text string (character), a data set (data.frame), or even more complex data structures.\nObjects in R can be created, modified, and used to perform various operations. Objects are assigned names that you can then use to reference them in your code. When you create an object, you’re essentially creating a container that holds a value or data.\nCreating an object is straightforward. First, we give it a name, then we use the assignment operator to assign it a value. The assignment operator (&lt;-) assigns the value on the right of the &lt;- to the object on the left8.8 Start building good habits starting now in terms of your coding style. For example, your code is a lot more readable if you use white space to your advantage. For example, make sure you have a space before and after your &lt;-\nExecute the code in the code chunk below by placing your cursor somewhere in the line of code and hitting Ctrl + Enter or by clicking on the little green arrow on the right hand side of the code chunk.\n\n# create object\nlength_mm &lt;- 344\n\nIf you look at your Global Environment (bottom left panel) you should now see length and the value you assigned it.\nNotice, how when you assigned a value to your new object nothing was printed in the console compared to when you were typing in math.\nTo print the value of an object you can type the name of the object into the console.\n\n# print value in the console\nlength_mm\n\n[1] 344\n\n\nNow that length is in your environment we can use it to compute instead of the value itself.\nFor example, we might need to convert our length from millimeters (mm) to centimeters (cm).\n\n# divide value of object by 10\nlength_mm / 10\n\n[1] 34.4\n\n\nWe can change the value of an object any time by assigning it a new one. Changing the value of one object does not change the values of other objects.\n\n# assign new value\nlength_mm &lt;- 567\n\n\n\n\n\n\n\nGive it a try\n\n\n\nCreate a new object called length_cm with the length in centimeters. Then change the value of our object with the length in millimeters to 50. What do you think the value of length_cm will be now?\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n# create object with length in cm\nlength_cm &lt;- length_mm / 10\n\n# change value\nlength_mm &lt;- 50\n\nYou should see that only the length_mm variable has changed but not the length_cm object. Those are completely independent from each other even though you initially used the length_mm object to create the other one.\n\n\n\n\n\n\n\n\n\nProtip\n\n\n\nTheoretically, we can name objects anything we want - but before that gets out of hand let’s think about some guidelines for naming objects.\n\nMake them simple, specific, and not too long (otherwise you will end up with a lot of typing to do and difficulties remembering which object is which).\nObject names cannot start with a number.\nR is case sensitive, length_mm is not the same as Length_mm.\nAvoid using dots (.) in names. Typically dots are used in function names and also have special meaning (methods) in R.\nSome names are already taken by fundamental functions (e.g. if, else, for) and cannot be used as names for objects; in general avoid using names that have already been used by other function names.\nRule of thumb: nouns for object names, verbs for function names.\n\nThis semester you will mostly execute code already written for you or make minimal modifications. However, be observant of the coding style and mimic it to develop good practices. Using a consistent style for naming your objects is part of adopting a consistent styling of your code; this includes things like spacing, how you name objects, and upper/lower case. Clean, consistent code will make following your code a lot easier for yourself and others."
  },
  {
    "objectID": "D01_intro-R.html#sec-using-comments",
    "href": "D01_intro-R.html#sec-using-comments",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.5 Using comments",
    "text": "3.5 Using comments\nYou can add comments to your R scripts using #. Essentially, once you type an # in a line anything to the right of it will be ignored.\nThis is really helpful as it will allow you to comment your script, i.e. you can leave notes and explanations as to what your code is doing for future you and for other collaborators. This is especially helpful if you come back to some of your code after a period of time, if you are sharing your code with others, and when you are debugging code. You will find that as you become more experienced your comments will become shorter and more concise and you might even be tempted to leave them out completely - don’t9!9 To help you build a habit of good commenting practice, commenting your code is a requirement for your homework assignment and skills tests.\nYou can add comments above or next to a line of code. For detailed comments you may want to include multiple lines of comments but you will need to add a # for every line of comment.\n\n\n\n\n\n\nGive it a try\n\n\n\nExecute this code line by line by placing your cursor above the first comment and hitting Ctrl + Enter and compare differences in behavior.\n\n# total length fish\nlength_mm &lt;- 436\n\nlength_mm &lt;- 436  # total length fish\n\n# total length of fish\n# this measurement is in millimeters\nlength_mm &lt;- 436\n\n\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can comment/uncomment multiple lines at once by highlighting the lines you want to comment (or uncomment) and hitting Ctrl + Shift + C. This can be useful if you are playing around with code and don’t want to delete something but don’t want it to be run either."
  },
  {
    "objectID": "D01_intro-R.html#sec-functions",
    "href": "D01_intro-R.html#sec-functions",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.6 Functions",
    "text": "3.6 Functions\nWhen we installed R packages earlier we mentioned that they comprise sets of predefined functions. These are essentially mini-scripts that automate using specific sets of commands. So instead of having to run multiple lines of code (this can be 10s - 100s of lines code) you call the function instead.\nEach function usually requires multiple inputs (arguments) and once executed will generally return a value .\nFor example the function round() can be used to round a number10.10 This is an excellent example of naming things well!\n\n# create object with rounded number\nlength_cm &lt;- round(34.8821)\n\nIf we print the value of our object to the console, we see the following value is returned.\n\n# call vector\nlength_cm\n\n[1] 35\n\n\nFor this function the input (argument) is a number and the returned value is also a number. This is not always the case, arguments can be numbers, objects, file paths …\nMany functions have set of arguments that alter the way a function operates - these are referred to as options. Generally, they have a default value which are used unless specified otherwise by the user.\nYou can determine the arguments as function by calling the function args().\n\n# query arguments\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nOr you can call up the help page using ?round or by typing it into the search box in the Help tab in the lower right panel.\nFor example, our round() function has an argument called digits, we can use this to specify the number of significant digits we want our rounded value to have.\n\n# round value to two digits\nround(34.8821, digits = 2)\n\n[1] 34.88\n\n\n\n\n\n\n\n\nProtip\n\n\n\nGood code style is to put the non-optional arguments (frequently the object, file path or value you are using) first and then specify the names of all the optional arguments you are specifying. This provides clarity and makes it easier for yourself and others to follow your code.\n\n\nOccasionally you might even want to use comments to further specify what each argument is doing or why you are choosing a specific option.\n\nround(34.8821,     # number to round\n      digits = 2)  # specify number of significant digits\n\n[1] 34.88"
  },
  {
    "objectID": "D01_intro-R.html#sec-data-types-i-vectors",
    "href": "D01_intro-R.html#sec-data-types-i-vectors",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.7 Data Types I: Vectors",
    "text": "3.7 Data Types I: Vectors\nNow that we’ve figured out what objects and functions are let’s get to know the two data types we will be spending the most time with this semester - vectors and data frames (data.frame)11.11 Other data types include lists (list), factors (factor) matrices (matrix), and arrays (array).\nThe most simple data type in R is the (atomic) vector which is a linear vector of a single type. There are six main types -\n\ncharacter: strings or words.\nnumeric or double: numbers.\ninteger: integer numbers (usually indicated as 2L to distinguish from numeric).\nlogical: TRUE or FALSE (i.e. boolean data type).\ncomplex: complex numbers with real and imaginary parts (we’ll leave it at that).\nraw: bitstreams (we won’t use those either).\n\nYou can check the data type of any object using class().\n\n# query class of object\nclass(length_mm)\n\n[1] \"numeric\"\n\n\nCurrently, our length_mm object consists of a single value. The function c() (concatenate) will allow us to assign a series of values to an object.\n\n# create numerical vector\nlength_mm &lt;- c(454, 234, 948, 201)\n\n# print to console\nlength_mm\n\n[1] 454 234 948 201\n\n\n\n\n\n\n\n\nConsider this\n\n\n\nPredict what data type you expect this vector to be.\n\n\nWe call the same function to create a character vector.\n\n# create character vector\nspecies &lt;- c(\"Adelie\", \"Gentoo\", \"Chinstrap\")\n\n# query class\nclass(species)\n\n[1] \"character\"\n\n\nThe quotes around \"Adelie\" etc. are essential because they indicate that this is a character.\n\n\n\n\n\n\nProtip\n\n\n\nIf we do not use quotes, R will assume that we are trying to call an object and you will get an error code along the lines of “! object 'Adelie' not found”.\n\n\nYou can use c() to combine an existing object with additional elements (assuming they are the same data type).\n\n# add element to vector\nspecies &lt;- c(species, \"Emperor\")\n\n# call vector\nspecies\n\n[1] \"Adelie\"    \"Gentoo\"    \"Chinstrap\" \"Emperor\""
  },
  {
    "objectID": "D01_intro-R.html#sec-data-types-ii-data-frames",
    "href": "D01_intro-R.html#sec-data-types-ii-data-frames",
    "title": "3  Introduction to R and Rstudio",
    "section": "3.8 Data Types II: Data frames",
    "text": "3.8 Data Types II: Data frames\nRecall that atomic vectors are linear vectors of a simple type, essentially they are one dimensional. Frequently we will be using data frames (data.frame) which you can think of as consisting of several vectors of the same length where each vector becomes a column and the elements are the rows.\nLet’s create a new object that is a data.frame with three columns containing information on species and length in millimeters.\n\n# combine vectors into data frame\ndf &lt;- data.frame(species, length_mm)\n\nYou should now see a new object in your Global Environment and you will now also see that there are two categories of objects Data and Values. You will see that the data.frame is described as having 3 obs (observations, those are your rows) of 2 variables (those are your columns). If you click on the little blue arrow it will give you additional information on each column - note that because each column is essentially a vector, each one must consist of a single data type which is also indicated.\nYou can further inspect the data.frame by clicking on the little white box on the right which will open a tab in the top left panel next to your R script. You can also always view a data.frame by calling the View() function.\n\n# view data frame in View Panes\nView(df)\n\nThis can be a helpful way to explore your data.frame, for example, clicking on the headers will sort the data frame by that column. Usually we won’t build or data.frames by hand, rather we will read them in from e.g. a tab-delimited text file - but more on that later."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Conservation Biology",
    "section": "",
    "text": "Overview\nWelcome to our lab handbook for Conservation Biology (Fall 2024) - it will be continuously updated throughout the semester. For the most part an electronic copy is sufficient1, if you need to print anything for a class I will let you know.1 You can go “split screen” on your laptop which will allow you to cut and paste code if needed or if you have a tablet you can pull up the manual there which gives you a better simultaneous viewing experience but then you cannot cut and paste text between the manual and Rstudio\nOver the course of ths semester we will be exploring a set of headwater streams in the Piscataquog watershed that are located around Francestown and New Boston that have been monitored by faculty at Saint Anselm College for &gt;15 years.\nWe will do this in three units. First, we will explore hydrological, physical, and chemical characteristics of the Piscataquog and a set of headwater streams. Then we will explore the macroinvertebrate biodiversity as bioindicators for ecosystem health. Finally, we will use environmental DNA to determine which of these stream currently function as brook trout habitat. At the end of the semester, we will consider how our eocystem health assessment can be used to inform management and conservation efforts of these important headwater ecosystems.\nThroughout the semester we will communicate our findings with visitors in Goulet by (re)designing a poster board."
  }
]